# LLM Provider Configuration
# Options: local, openai, anthropic, bedrock
LLM_PROVIDER=local

# Local (LM Studio) - default
LLM_BASE_URL=http://localhost:1234/v1
LLM_MODEL=local-model

# OpenAI (set LLM_PROVIDER=openai)
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4o
# OPENAI_API_KEY=sk-...

# Anthropic (set LLM_PROVIDER=anthropic)
# LLM_MODEL=claude-sonnet-4-20250514
# ANTHROPIC_API_KEY=sk-ant-...

# AWS Bedrock (set LLM_PROVIDER=bedrock)
# LLM_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
# AWS_REGION=us-west-1
# Option 1: Use explicit credentials
# AWS_ACCESS_KEY_ID=AKIA...
# AWS_SECRET_ACCESS_KEY=...
# Option 2: Leave blank to use ~/.aws/credentials or IAM role
