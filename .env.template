# LLM Provider Configuration
# Options: local, openai, anthropic, bedrock
LLM_PROVIDER=local

# Local (LM Studio) - default
LLM_BASE_URL=http://localhost:1234/v1
LLM_MODEL=local-model

# OpenAI (set LLM_PROVIDER=openai)
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4o
# OPENAI_API_KEY=sk-...

# Anthropic (set LLM_PROVIDER=anthropic)
# LLM_MODEL=claude-sonnet-4-20250514
# ANTHROPIC_API_KEY=sk-ant-...

# AWS Bedrock (set LLM_PROVIDER=bedrock)
# LLM_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
# AWS_REGION=us-west-1
#
# Option 1: Use SSO profile (recommended for IAM Identity Center)
# AWS_PROFILE=your-sso-profile
#
# Option 2: Temporary credentials from SSO portal (https://usr.awsapps.com/start/#)
# AWS_ACCESS_KEY_ID=ASIA...
# AWS_SECRET_ACCESS_KEY=...
# AWS_SESSION_TOKEN=...
#
# Option 3: IAM user credentials (no session token needed)
# AWS_ACCESS_KEY_ID=AKIA...
# AWS_SECRET_ACCESS_KEY=...
